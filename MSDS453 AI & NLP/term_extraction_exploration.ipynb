{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dr. Jennifer Sleeman\n",
    "# Exploring Term Extraction Methods\n",
    "# jennifer.sleeman@northwestern.edu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting phrasemachine\n",
      "  Downloading phrasemachine-1.0.7.tar.gz (2.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.7 MB 2.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: nltk in /Users/kevhhu/opt/anaconda3/lib/python3.8/site-packages (from phrasemachine) (3.6.1)\n",
      "Requirement already satisfied: click in /Users/kevhhu/opt/anaconda3/lib/python3.8/site-packages (from nltk->phrasemachine) (7.1.2)\n",
      "Requirement already satisfied: joblib in /Users/kevhhu/opt/anaconda3/lib/python3.8/site-packages (from nltk->phrasemachine) (1.3.2)\n",
      "Requirement already satisfied: tqdm in /Users/kevhhu/opt/anaconda3/lib/python3.8/site-packages (from nltk->phrasemachine) (4.59.0)\n",
      "Requirement already satisfied: regex in /Users/kevhhu/opt/anaconda3/lib/python3.8/site-packages (from nltk->phrasemachine) (2021.4.4)\n",
      "Building wheels for collected packages: phrasemachine\n",
      "  Building wheel for phrasemachine (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for phrasemachine: filename=phrasemachine-1.0.7-py3-none-any.whl size=2694881 sha256=a7158aa9235613f2f81d49f470e60927c8a6fd6adfbfb0aacf18ba760447c1ee\n",
      "  Stored in directory: /Users/kevhhu/Library/Caches/pip/wheels/2d/9e/9c/e59fe753d4541789d76201dc96d02927baccc82069679097dc\n",
      "Successfully built phrasemachine\n",
      "Installing collected packages: phrasemachine\n",
      "Successfully installed phrasemachine-1.0.7\n",
      "Requirement already satisfied: nltk in /Users/kevhhu/opt/anaconda3/lib/python3.8/site-packages (3.6.1)\n",
      "Requirement already satisfied: click in /Users/kevhhu/opt/anaconda3/lib/python3.8/site-packages (from nltk) (7.1.2)\n",
      "Requirement already satisfied: regex in /Users/kevhhu/opt/anaconda3/lib/python3.8/site-packages (from nltk) (2021.4.4)\n",
      "Requirement already satisfied: tqdm in /Users/kevhhu/opt/anaconda3/lib/python3.8/site-packages (from nltk) (4.59.0)\n",
      "Requirement already satisfied: joblib in /Users/kevhhu/opt/anaconda3/lib/python3.8/site-packages (from nltk) (1.3.2)\n",
      "Collecting rake_nltk\n",
      "  Downloading rake_nltk-1.0.6-py3-none-any.whl (9.1 kB)\n",
      "Collecting nltk<4.0.0,>=3.6.2\n",
      "  Downloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.5 MB 2.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: tqdm in /Users/kevhhu/opt/anaconda3/lib/python3.8/site-packages (from nltk<4.0.0,>=3.6.2->rake_nltk) (4.59.0)\n",
      "Collecting regex>=2021.8.3\n",
      "  Downloading regex-2023.12.25-cp38-cp38-macosx_10_9_x86_64.whl (296 kB)\n",
      "\u001b[K     |████████████████████████████████| 296 kB 49.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: joblib in /Users/kevhhu/opt/anaconda3/lib/python3.8/site-packages (from nltk<4.0.0,>=3.6.2->rake_nltk) (1.3.2)\n",
      "Requirement already satisfied: click in /Users/kevhhu/opt/anaconda3/lib/python3.8/site-packages (from nltk<4.0.0,>=3.6.2->rake_nltk) (7.1.2)\n",
      "Installing collected packages: regex, nltk, rake-nltk\n",
      "  Attempting uninstall: regex\n",
      "    Found existing installation: regex 2021.4.4\n",
      "    Uninstalling regex-2021.4.4:\n",
      "      Successfully uninstalled regex-2021.4.4\n",
      "  Attempting uninstall: nltk\n",
      "    Found existing installation: nltk 3.6.1\n",
      "    Uninstalling nltk-3.6.1:\n",
      "      Successfully uninstalled nltk-3.6.1\n",
      "Successfully installed nltk-3.8.1 rake-nltk-1.0.6 regex-2023.12.25\n"
     ]
    }
   ],
   "source": [
    "#Just in case you need to install the appropriate packages uncomment these lines\n",
    "!pip3 install phrasemachine\n",
    "!pip3 install nltk\n",
    "!pip3 install rake_nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/kevhhu/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import phrasemachine\n",
    "import nltk\n",
    "from rake_nltk import Rake\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize \n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk import ngrams, FreqDist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/kevhhu/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
      "[nltk_data] Downloading package wordnet to /Users/kevhhu/nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Only run this once, they will be downloaded.\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examples\n",
    "document1 = \"\"\" For their sauces alone, I'm willing to say Via Rosa puts out some of the best-tasting food on the island. All of the sauces I've tried there taste like something homemade, like they took a good deal of time and effort to make. Definitely a step above the average around here. That said, for the price, the pizza and pasta itself fell a little bit short of expectations.\n",
    "\n",
    "The pizza dough itself is very thin, very crisp, and has a nice flavor. Their marinara, like all their other sauces, is bright and tasty. Despite this, their margherita pizza was seriously underwhelming - the way the basil was on the pizza was a little sad but the real killer was the apparent lack of fresh mozzarella - it tasted a lot more like a parmesan pizza than anything else. Just seemed like a really strange thing to skimp out on, and based on other pictures it seems like going super light on the cheese may just be the standard here. In any case, I think there are better places to go for pizza on the island, thin-crust or otherwise (especially for the price!!)\n",
    "\n",
    "I didn't really take any particular issue with the noodles themselves (they weren't *unpleasant* to eat or anything) but the texture wasn't amazing and they've just never really impressed. Additionally, it's a little strange how long it took to get food given how fast fresh pasta takes to cook, their having sauces pre-prepared, and the size of their kitchen. But if you order ahead of time this probably isn't much of an issue - they seem to be doing a lot of take-out business.\n",
    "\n",
    "Cannoli was ok, not very sweet. Nice of them to have it at such a low price, one of my dining companions felt sure they were store-bought but I would probably still get one again.\n",
    "\n",
    "Altogether, it's far from bad food, and the location is pretty nice - they give you a good deal of options for take-home food, I like their \"market\" section. I'm not sure if I'd describe it as a \"must-try\" place - even at its best, it feels expensive for what you get. Still, I'd say it's one of the better restaurants on Bainbridge if money is no object. Kind of an iconic little location (Rolling Bay) to visit off the beaten path if you're a tourist. People definitely like this place for a reason.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of stop words from nltk\n",
    "stop_words = set(stopwords.words(\"english\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-process dataset to remove punctuation\n",
    "def remove_punctuation(in_text):\n",
    "    # Remove punctuation\n",
    "    text = re.sub('[^a-zA-Z]', ' ', str(in_text))\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-process dataset to lower case it\n",
    "def lower_case(in_text):\n",
    "    # Convert to lowercase\n",
    "    text = in_text.lower()    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-process dataset to remove tags\n",
    "def remove_tags(in_text):    \n",
    "    # Remove tags\n",
    "    text=re.sub(\"&lt;/?.*?&gt;\",\" &lt;&gt; \",in_text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-process dataset to remove special characters and digits\n",
    "def remove_special_chars_and_digits(in_text):\n",
    "    # Remove special characters and digits\n",
    "    text=re.sub(\"(\\\\d|\\\\W)+\",\" \",in_text)\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-process dataset to appy Stemming\n",
    "def apply_stemming(in_text):\n",
    "    stemmer=PorterStemmer()\n",
    "    word_list = nltk.word_tokenize(in_text)\n",
    "    output = ' '.join([stemmer.stem(w) for w in word_list])\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-process dataset to apply Lemmatization\n",
    "def apply_lemmatization(in_text):\n",
    "    # Lemmatization\n",
    "    lem = WordNetLemmatizer()\n",
    "    word_list = nltk.word_tokenize(in_text)\n",
    "    output = ' '.join([lem.lemmatize(w) for w in word_list])\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove stop words\n",
    "def remove_stop_words(in_text):\n",
    "    stop_words = set(stopwords.words('english')) \n",
    "    word_tokens = word_tokenize(in_text)  \n",
    "    filtered_sentence = [w for w in word_tokens if not w in stop_words] \n",
    "    filtered_sentence = [] \n",
    "    for w in word_tokens: \n",
    "        if w not in stop_words: \n",
    "            filtered_sentence.append(w) \n",
    "\n",
    "    return filtered_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Phase Machine\n",
    "def run_phrase_machine(in_text):\n",
    "    phrases=phrasemachine.get_phrases(in_text)\n",
    "    return phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run Rake Keyword Extractor\n",
    "def run_rake(in_text):\n",
    "    r = Rake()\n",
    "    r.extract_keywords_from_text(in_text)\n",
    "    rake_phrases= r.get_ranked_phrases()\n",
    "    return rake_phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run NLTK Tokenizer\n",
    "def run_nltk_tokenizer(in_text):\n",
    "    tokens=nltk.word_tokenize(in_text)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run NLTK Sentence Tokenizer\n",
    "def run_nltk_sent_tokenizer(in_corpus):\n",
    "    sents = nltk.sent_tokenize(in_corpus)\n",
    "    return sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run word-ngram Tokenizer\n",
    "def run_nltk_tokenizer_word_ngrams(in_text, ngram_size):\n",
    "    n_grams = ngrams(nltk.word_tokenize(in_text), ngram_size)\n",
    "    return [ ' '.join(grams) for grams in n_grams]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get Frequ Dist \n",
    "def get_freq_dist(terms):\n",
    "    all_counts = dict()\n",
    "    all_counts = FreqDist(terms)\n",
    "    return all_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run this first to get sentences from text.\n",
    "sentences=run_nltk_sent_tokenizer(document1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " For their sauces alone, I'm willing to say Via Rosa puts out some of the best-tasting food on the island.\n",
      "===================NLTK Tokenizer===================\n",
      "['For', 'their', 'sauces', 'alone', ',', 'I', \"'m\", 'willing', 'to', 'say', 'Via', 'Rosa', 'puts', 'out', 'some', 'of', 'the', 'best-tasting', 'food', 'on', 'the', 'island', '.']\n",
      "===================NLTK Word NGRAM Tokenizer 2 words===================\n",
      "['For their', 'their sauces', 'sauces alone', 'alone ,', ', I', \"I 'm\", \"'m willing\", 'willing to', 'to say', 'say Via', 'Via Rosa', 'Rosa puts', 'puts out', 'out some', 'some of', 'of the', 'the best-tasting', 'best-tasting food', 'food on', 'on the', 'the island', 'island .']\n",
      "===================NLTK Word NGRAM Tokenizer 3 words===================\n",
      "['For their sauces', 'their sauces alone', 'sauces alone ,', 'alone , I', \", I 'm\", \"I 'm willing\", \"'m willing to\", 'willing to say', 'to say Via', 'say Via Rosa', 'Via Rosa puts', 'Rosa puts out', 'puts out some', 'out some of', 'some of the', 'of the best-tasting', 'the best-tasting food', 'best-tasting food on', 'food on the', 'on the island', 'the island .']\n",
      "===================Phrase Machine===================\n",
      "via rosa\n",
      "best-tasting food\n",
      "best-tasting food on the island\n",
      "food on the island\n",
      "===================Rake===================\n",
      "['say via rosa puts', 'tasting food', 'sauces alone', 'willing', 'island', 'best']\n",
      "===================NLTK Tokenizer===================\n",
      "['For', 'their', 'sauces', 'alone', ',', 'I', \"'m\", 'willing', 'to', 'say', 'Via', 'Rosa', 'puts', 'out', 'some', 'of', 'the', 'best-tasting', 'food', 'on', 'the', 'island', '.']\n",
      "===================NLTK Tokenizer LOWER CASE===================\n",
      "['for', 'their', 'sauces', 'alone', ',', 'i', \"'m\", 'willing', 'to', 'say', 'via', 'rosa', 'puts', 'out', 'some', 'of', 'the', 'best-tasting', 'food', 'on', 'the', 'island', '.']\n",
      "===================NLTK Tokenizer REMOVE STOP WORDS===================\n",
      "['For', 'sauces', 'alone', ',', 'I', \"'m\", 'willing', 'say', 'Via', 'Rosa', 'puts', 'best-tasting', 'food', 'island', '.']\n",
      "===================NLTK Tokenizer REMOVED PUNCTUATION===================\n",
      "['For', 'their', 'sauces', 'alone', 'I', 'm', 'willing', 'to', 'say', 'Via', 'Rosa', 'puts', 'out', 'some', 'of', 'the', 'best', 'tasting', 'food', 'on', 'the', 'island']\n",
      "===================NLTK Tokenizer REMOVED TAGS===================\n",
      "['For', 'their', 'sauces', 'alone', ',', 'I', \"'m\", 'willing', 'to', 'say', 'Via', 'Rosa', 'puts', 'out', 'some', 'of', 'the', 'best-tasting', 'food', 'on', 'the', 'island', '.']\n",
      "===================NLTK Tokenizer REMOVED CHARS AND DIGITS===================\n",
      "['For', 'their', 'sauces', 'alone', 'I', 'm', 'willing', 'to', 'say', 'Via', 'Rosa', 'puts', 'out', 'some', 'of', 'the', 'best', 'tasting', 'food', 'on', 'the', 'island']\n",
      "===================NLTK Tokenizer STEMMING APPLIED===================\n",
      "['for', 'their', 'sauc', 'alon', ',', 'i', \"'m\", 'will', 'to', 'say', 'via', 'rosa', 'put', 'out', 'some', 'of', 'the', 'best-tast', 'food', 'on', 'the', 'island', '.']\n",
      "===================NLTK Tokenizer LEMMATIZATION APPLIED===================\n",
      "['For', 'their', 'sauce', 'alone', ',', 'I', \"'m\", 'willing', 'to', 'say', 'Via', 'Rosa', 'put', 'out', 'some', 'of', 'the', 'best-tasting', 'food', 'on', 'the', 'island', '.']\n",
      "All of the sauces I've tried there taste like something homemade, like they took a good deal of time and effort to make.\n",
      "===================NLTK Tokenizer===================\n",
      "['All', 'of', 'the', 'sauces', 'I', \"'ve\", 'tried', 'there', 'taste', 'like', 'something', 'homemade', ',', 'like', 'they', 'took', 'a', 'good', 'deal', 'of', 'time', 'and', 'effort', 'to', 'make', '.']\n",
      "===================NLTK Word NGRAM Tokenizer 2 words===================\n",
      "['All of', 'of the', 'the sauces', 'sauces I', \"I 've\", \"'ve tried\", 'tried there', 'there taste', 'taste like', 'like something', 'something homemade', 'homemade ,', ', like', 'like they', 'they took', 'took a', 'a good', 'good deal', 'deal of', 'of time', 'time and', 'and effort', 'effort to', 'to make', 'make .']\n",
      "===================NLTK Word NGRAM Tokenizer 3 words===================\n",
      "['All of the', 'of the sauces', 'the sauces I', \"sauces I 've\", \"I 've tried\", \"'ve tried there\", 'tried there taste', 'there taste like', 'taste like something', 'like something homemade', 'something homemade ,', 'homemade , like', ', like they', 'like they took', 'they took a', 'took a good', 'a good deal', 'good deal of', 'deal of time', 'of time and', 'time and effort', 'and effort to', 'effort to make', 'to make .']\n",
      "===================Phrase Machine===================\n",
      "taste like something\n",
      "taste like something homemade\n",
      "something homemade\n",
      "good deal\n",
      "good deal of time\n",
      "deal of time\n",
      "===================Rake===================\n",
      "['taste like something homemade', 'good deal', 'like', 'tried', 'took', 'time', 'sauces', 'make', 'effort']\n",
      "===================NLTK Tokenizer===================\n",
      "['All', 'of', 'the', 'sauces', 'I', \"'ve\", 'tried', 'there', 'taste', 'like', 'something', 'homemade', ',', 'like', 'they', 'took', 'a', 'good', 'deal', 'of', 'time', 'and', 'effort', 'to', 'make', '.']\n",
      "===================NLTK Tokenizer LOWER CASE===================\n",
      "['all', 'of', 'the', 'sauces', 'i', \"'ve\", 'tried', 'there', 'taste', 'like', 'something', 'homemade', ',', 'like', 'they', 'took', 'a', 'good', 'deal', 'of', 'time', 'and', 'effort', 'to', 'make', '.']\n",
      "===================NLTK Tokenizer REMOVE STOP WORDS===================\n",
      "['All', 'sauces', 'I', \"'ve\", 'tried', 'taste', 'like', 'something', 'homemade', ',', 'like', 'took', 'good', 'deal', 'time', 'effort', 'make', '.']\n",
      "===================NLTK Tokenizer REMOVED PUNCTUATION===================\n",
      "['All', 'of', 'the', 'sauces', 'I', 've', 'tried', 'there', 'taste', 'like', 'something', 'homemade', 'like', 'they', 'took', 'a', 'good', 'deal', 'of', 'time', 'and', 'effort', 'to', 'make']\n",
      "===================NLTK Tokenizer REMOVED TAGS===================\n",
      "['All', 'of', 'the', 'sauces', 'I', \"'ve\", 'tried', 'there', 'taste', 'like', 'something', 'homemade', ',', 'like', 'they', 'took', 'a', 'good', 'deal', 'of', 'time', 'and', 'effort', 'to', 'make', '.']\n",
      "===================NLTK Tokenizer REMOVED CHARS AND DIGITS===================\n",
      "['All', 'of', 'the', 'sauces', 'I', 've', 'tried', 'there', 'taste', 'like', 'something', 'homemade', 'like', 'they', 'took', 'a', 'good', 'deal', 'of', 'time', 'and', 'effort', 'to', 'make']\n",
      "===================NLTK Tokenizer STEMMING APPLIED===================\n",
      "['all', 'of', 'the', 'sauc', 'i', \"'ve\", 'tri', 'there', 'tast', 'like', 'someth', 'homemad', ',', 'like', 'they', 'took', 'a', 'good', 'deal', 'of', 'time', 'and', 'effort', 'to', 'make', '.']\n",
      "===================NLTK Tokenizer LEMMATIZATION APPLIED===================\n",
      "['All', 'of', 'the', 'sauce', 'I', \"'ve\", 'tried', 'there', 'taste', 'like', 'something', 'homemade', ',', 'like', 'they', 'took', 'a', 'good', 'deal', 'of', 'time', 'and', 'effort', 'to', 'make', '.']\n",
      "Definitely a step above the average around here.\n",
      "===================NLTK Tokenizer===================\n",
      "['Definitely', 'a', 'step', 'above', 'the', 'average', 'around', 'here', '.']\n",
      "===================NLTK Word NGRAM Tokenizer 2 words===================\n",
      "['Definitely a', 'a step', 'step above', 'above the', 'the average', 'average around', 'around here', 'here .']\n",
      "===================NLTK Word NGRAM Tokenizer 3 words===================\n",
      "['Definitely a step', 'a step above', 'step above the', 'above the average', 'the average around', 'average around here', 'around here .']\n",
      "===================Phrase Machine===================\n",
      "step above the average\n",
      "===================Rake===================\n",
      "['average around', 'step', 'definitely']\n",
      "===================NLTK Tokenizer===================\n",
      "['Definitely', 'a', 'step', 'above', 'the', 'average', 'around', 'here', '.']\n",
      "===================NLTK Tokenizer LOWER CASE===================\n",
      "['definitely', 'a', 'step', 'above', 'the', 'average', 'around', 'here', '.']\n",
      "===================NLTK Tokenizer REMOVE STOP WORDS===================\n",
      "['Definitely', 'step', 'average', 'around', '.']\n",
      "===================NLTK Tokenizer REMOVED PUNCTUATION===================\n",
      "['Definitely', 'a', 'step', 'above', 'the', 'average', 'around', 'here']\n",
      "===================NLTK Tokenizer REMOVED TAGS===================\n",
      "['Definitely', 'a', 'step', 'above', 'the', 'average', 'around', 'here', '.']\n",
      "===================NLTK Tokenizer REMOVED CHARS AND DIGITS===================\n",
      "['Definitely', 'a', 'step', 'above', 'the', 'average', 'around', 'here']\n",
      "===================NLTK Tokenizer STEMMING APPLIED===================\n",
      "['definit', 'a', 'step', 'abov', 'the', 'averag', 'around', 'here', '.']\n",
      "===================NLTK Tokenizer LEMMATIZATION APPLIED===================\n",
      "['Definitely', 'a', 'step', 'above', 'the', 'average', 'around', 'here', '.']\n",
      "That said, for the price, the pizza and pasta itself fell a little bit short of expectations.\n",
      "===================NLTK Tokenizer===================\n",
      "['That', 'said', ',', 'for', 'the', 'price', ',', 'the', 'pizza', 'and', 'pasta', 'itself', 'fell', 'a', 'little', 'bit', 'short', 'of', 'expectations', '.']\n",
      "===================NLTK Word NGRAM Tokenizer 2 words===================\n",
      "['That said', 'said ,', ', for', 'for the', 'the price', 'price ,', ', the', 'the pizza', 'pizza and', 'and pasta', 'pasta itself', 'itself fell', 'fell a', 'a little', 'little bit', 'bit short', 'short of', 'of expectations', 'expectations .']\n",
      "===================NLTK Word NGRAM Tokenizer 3 words===================\n",
      "['That said ,', 'said , for', ', for the', 'for the price', 'the price ,', 'price , the', ', the pizza', 'the pizza and', 'pizza and pasta', 'and pasta itself', 'pasta itself fell', 'itself fell a', 'fell a little', 'a little bit', 'little bit short', 'bit short of', 'short of expectations', 'of expectations .']\n",
      "===================Phrase Machine===================\n",
      "little bit\n",
      "===================Rake===================\n",
      "['little bit short', 'said', 'price', 'pizza', 'pasta', 'fell', 'expectations']\n",
      "===================NLTK Tokenizer===================\n",
      "['That', 'said', ',', 'for', 'the', 'price', ',', 'the', 'pizza', 'and', 'pasta', 'itself', 'fell', 'a', 'little', 'bit', 'short', 'of', 'expectations', '.']\n",
      "===================NLTK Tokenizer LOWER CASE===================\n",
      "['that', 'said', ',', 'for', 'the', 'price', ',', 'the', 'pizza', 'and', 'pasta', 'itself', 'fell', 'a', 'little', 'bit', 'short', 'of', 'expectations', '.']\n",
      "===================NLTK Tokenizer REMOVE STOP WORDS===================\n",
      "['That', 'said', ',', 'price', ',', 'pizza', 'pasta', 'fell', 'little', 'bit', 'short', 'expectations', '.']\n",
      "===================NLTK Tokenizer REMOVED PUNCTUATION===================\n",
      "['That', 'said', 'for', 'the', 'price', 'the', 'pizza', 'and', 'pasta', 'itself', 'fell', 'a', 'little', 'bit', 'short', 'of', 'expectations']\n",
      "===================NLTK Tokenizer REMOVED TAGS===================\n",
      "['That', 'said', ',', 'for', 'the', 'price', ',', 'the', 'pizza', 'and', 'pasta', 'itself', 'fell', 'a', 'little', 'bit', 'short', 'of', 'expectations', '.']\n",
      "===================NLTK Tokenizer REMOVED CHARS AND DIGITS===================\n",
      "['That', 'said', 'for', 'the', 'price', 'the', 'pizza', 'and', 'pasta', 'itself', 'fell', 'a', 'little', 'bit', 'short', 'of', 'expectations']\n",
      "===================NLTK Tokenizer STEMMING APPLIED===================\n",
      "['that', 'said', ',', 'for', 'the', 'price', ',', 'the', 'pizza', 'and', 'pasta', 'itself', 'fell', 'a', 'littl', 'bit', 'short', 'of', 'expect', '.']\n",
      "===================NLTK Tokenizer LEMMATIZATION APPLIED===================\n",
      "['That', 'said', ',', 'for', 'the', 'price', ',', 'the', 'pizza', 'and', 'pasta', 'itself', 'fell', 'a', 'little', 'bit', 'short', 'of', 'expectation', '.']\n",
      "The pizza dough itself is very thin, very crisp, and has a nice flavor.\n",
      "===================NLTK Tokenizer===================\n",
      "['The', 'pizza', 'dough', 'itself', 'is', 'very', 'thin', ',', 'very', 'crisp', ',', 'and', 'has', 'a', 'nice', 'flavor', '.']\n",
      "===================NLTK Word NGRAM Tokenizer 2 words===================\n",
      "['The pizza', 'pizza dough', 'dough itself', 'itself is', 'is very', 'very thin', 'thin ,', ', very', 'very crisp', 'crisp ,', ', and', 'and has', 'has a', 'a nice', 'nice flavor', 'flavor .']\n",
      "===================NLTK Word NGRAM Tokenizer 3 words===================\n",
      "['The pizza dough', 'pizza dough itself', 'dough itself is', 'itself is very', 'is very thin', 'very thin ,', 'thin , very', ', very crisp', 'very crisp ,', 'crisp , and', ', and has', 'and has a', 'has a nice', 'a nice flavor', 'nice flavor .']\n",
      "===================Phrase Machine===================\n",
      "nice flavor\n",
      "===================Rake===================\n",
      "['pizza dough', 'nice flavor', 'thin', 'crisp']\n",
      "===================NLTK Tokenizer===================\n",
      "['The', 'pizza', 'dough', 'itself', 'is', 'very', 'thin', ',', 'very', 'crisp', ',', 'and', 'has', 'a', 'nice', 'flavor', '.']\n",
      "===================NLTK Tokenizer LOWER CASE===================\n",
      "['the', 'pizza', 'dough', 'itself', 'is', 'very', 'thin', ',', 'very', 'crisp', ',', 'and', 'has', 'a', 'nice', 'flavor', '.']\n",
      "===================NLTK Tokenizer REMOVE STOP WORDS===================\n",
      "['The', 'pizza', 'dough', 'thin', ',', 'crisp', ',', 'nice', 'flavor', '.']\n",
      "===================NLTK Tokenizer REMOVED PUNCTUATION===================\n",
      "['The', 'pizza', 'dough', 'itself', 'is', 'very', 'thin', 'very', 'crisp', 'and', 'has', 'a', 'nice', 'flavor']\n",
      "===================NLTK Tokenizer REMOVED TAGS===================\n",
      "['The', 'pizza', 'dough', 'itself', 'is', 'very', 'thin', ',', 'very', 'crisp', ',', 'and', 'has', 'a', 'nice', 'flavor', '.']\n",
      "===================NLTK Tokenizer REMOVED CHARS AND DIGITS===================\n",
      "['The', 'pizza', 'dough', 'itself', 'is', 'very', 'thin', 'very', 'crisp', 'and', 'has', 'a', 'nice', 'flavor']\n",
      "===================NLTK Tokenizer STEMMING APPLIED===================\n",
      "['the', 'pizza', 'dough', 'itself', 'is', 'veri', 'thin', ',', 'veri', 'crisp', ',', 'and', 'ha', 'a', 'nice', 'flavor', '.']\n",
      "===================NLTK Tokenizer LEMMATIZATION APPLIED===================\n",
      "['The', 'pizza', 'dough', 'itself', 'is', 'very', 'thin', ',', 'very', 'crisp', ',', 'and', 'ha', 'a', 'nice', 'flavor', '.']\n",
      "Their marinara, like all their other sauces, is bright and tasty.\n",
      "===================NLTK Tokenizer===================\n",
      "['Their', 'marinara', ',', 'like', 'all', 'their', 'other', 'sauces', ',', 'is', 'bright', 'and', 'tasty', '.']\n",
      "===================NLTK Word NGRAM Tokenizer 2 words===================\n",
      "['Their marinara', 'marinara ,', ', like', 'like all', 'all their', 'their other', 'other sauces', 'sauces ,', ', is', 'is bright', 'bright and', 'and tasty', 'tasty .']\n",
      "===================NLTK Word NGRAM Tokenizer 3 words===================\n",
      "['Their marinara ,', 'marinara , like', ', like all', 'like all their', 'all their other', 'their other sauces', 'other sauces ,', 'sauces , is', ', is bright', 'is bright and', 'bright and tasty', 'and tasty .']\n",
      "===================Phrase Machine===================\n",
      "other sauces\n",
      "===================Rake===================\n",
      "['tasty', 'sauces', 'marinara', 'like', 'bright']\n",
      "===================NLTK Tokenizer===================\n",
      "['Their', 'marinara', ',', 'like', 'all', 'their', 'other', 'sauces', ',', 'is', 'bright', 'and', 'tasty', '.']\n",
      "===================NLTK Tokenizer LOWER CASE===================\n",
      "['their', 'marinara', ',', 'like', 'all', 'their', 'other', 'sauces', ',', 'is', 'bright', 'and', 'tasty', '.']\n",
      "===================NLTK Tokenizer REMOVE STOP WORDS===================\n",
      "['Their', 'marinara', ',', 'like', 'sauces', ',', 'bright', 'tasty', '.']\n",
      "===================NLTK Tokenizer REMOVED PUNCTUATION===================\n",
      "['Their', 'marinara', 'like', 'all', 'their', 'other', 'sauces', 'is', 'bright', 'and', 'tasty']\n",
      "===================NLTK Tokenizer REMOVED TAGS===================\n",
      "['Their', 'marinara', ',', 'like', 'all', 'their', 'other', 'sauces', ',', 'is', 'bright', 'and', 'tasty', '.']\n",
      "===================NLTK Tokenizer REMOVED CHARS AND DIGITS===================\n",
      "['Their', 'marinara', 'like', 'all', 'their', 'other', 'sauces', 'is', 'bright', 'and', 'tasty']\n",
      "===================NLTK Tokenizer STEMMING APPLIED===================\n",
      "['their', 'marinara', ',', 'like', 'all', 'their', 'other', 'sauc', ',', 'is', 'bright', 'and', 'tasti', '.']\n",
      "===================NLTK Tokenizer LEMMATIZATION APPLIED===================\n",
      "['Their', 'marinara', ',', 'like', 'all', 'their', 'other', 'sauce', ',', 'is', 'bright', 'and', 'tasty', '.']\n",
      "Despite this, their margherita pizza was seriously underwhelming - the way the basil was on the pizza was a little sad but the real killer was the apparent lack of fresh mozzarella - it tasted a lot more like a parmesan pizza than anything else.\n",
      "===================NLTK Tokenizer===================\n",
      "['Despite', 'this', ',', 'their', 'margherita', 'pizza', 'was', 'seriously', 'underwhelming', '-', 'the', 'way', 'the', 'basil', 'was', 'on', 'the', 'pizza', 'was', 'a', 'little', 'sad', 'but', 'the', 'real', 'killer', 'was', 'the', 'apparent', 'lack', 'of', 'fresh', 'mozzarella', '-', 'it', 'tasted', 'a', 'lot', 'more', 'like', 'a', 'parmesan', 'pizza', 'than', 'anything', 'else', '.']\n",
      "===================NLTK Word NGRAM Tokenizer 2 words===================\n",
      "['Despite this', 'this ,', ', their', 'their margherita', 'margherita pizza', 'pizza was', 'was seriously', 'seriously underwhelming', 'underwhelming -', '- the', 'the way', 'way the', 'the basil', 'basil was', 'was on', 'on the', 'the pizza', 'pizza was', 'was a', 'a little', 'little sad', 'sad but', 'but the', 'the real', 'real killer', 'killer was', 'was the', 'the apparent', 'apparent lack', 'lack of', 'of fresh', 'fresh mozzarella', 'mozzarella -', '- it', 'it tasted', 'tasted a', 'a lot', 'lot more', 'more like', 'like a', 'a parmesan', 'parmesan pizza', 'pizza than', 'than anything', 'anything else', 'else .']\n",
      "===================NLTK Word NGRAM Tokenizer 3 words===================\n",
      "['Despite this ,', 'this , their', ', their margherita', 'their margherita pizza', 'margherita pizza was', 'pizza was seriously', 'was seriously underwhelming', 'seriously underwhelming -', 'underwhelming - the', '- the way', 'the way the', 'way the basil', 'the basil was', 'basil was on', 'was on the', 'on the pizza', 'the pizza was', 'pizza was a', 'was a little', 'a little sad', 'little sad but', 'sad but the', 'but the real', 'the real killer', 'real killer was', 'killer was the', 'was the apparent', 'the apparent lack', 'apparent lack of', 'lack of fresh', 'of fresh mozzarella', 'fresh mozzarella -', 'mozzarella - it', '- it tasted', 'it tasted a', 'tasted a lot', 'a lot more', 'lot more like', 'more like a', 'like a parmesan', 'a parmesan pizza', 'parmesan pizza than', 'pizza than anything', 'than anything else', 'anything else .']\n",
      "===================Phrase Machine===================\n",
      "margherita pizza\n",
      "real killer\n",
      "apparent lack\n",
      "apparent lack of fresh mozzarella\n",
      "lack of fresh mozzarella\n",
      "fresh mozzarella\n",
      "parmesan pizza\n",
      "parmesan pizza than anything\n",
      "pizza than anything\n",
      "===================Rake===================\n",
      "['seriously underwhelming', 'real killer', 'little sad', 'fresh mozzarella', 'apparent lack', 'anything else', 'parmesan pizza', 'margherita pizza', 'pizza', 'way', 'tasted', 'lot', 'like', 'despite', 'basil']\n",
      "===================NLTK Tokenizer===================\n",
      "['Despite', 'this', ',', 'their', 'margherita', 'pizza', 'was', 'seriously', 'underwhelming', '-', 'the', 'way', 'the', 'basil', 'was', 'on', 'the', 'pizza', 'was', 'a', 'little', 'sad', 'but', 'the', 'real', 'killer', 'was', 'the', 'apparent', 'lack', 'of', 'fresh', 'mozzarella', '-', 'it', 'tasted', 'a', 'lot', 'more', 'like', 'a', 'parmesan', 'pizza', 'than', 'anything', 'else', '.']\n",
      "===================NLTK Tokenizer LOWER CASE===================\n",
      "['despite', 'this', ',', 'their', 'margherita', 'pizza', 'was', 'seriously', 'underwhelming', '-', 'the', 'way', 'the', 'basil', 'was', 'on', 'the', 'pizza', 'was', 'a', 'little', 'sad', 'but', 'the', 'real', 'killer', 'was', 'the', 'apparent', 'lack', 'of', 'fresh', 'mozzarella', '-', 'it', 'tasted', 'a', 'lot', 'more', 'like', 'a', 'parmesan', 'pizza', 'than', 'anything', 'else', '.']\n",
      "===================NLTK Tokenizer REMOVE STOP WORDS===================\n",
      "['Despite', ',', 'margherita', 'pizza', 'seriously', 'underwhelming', '-', 'way', 'basil', 'pizza', 'little', 'sad', 'real', 'killer', 'apparent', 'lack', 'fresh', 'mozzarella', '-', 'tasted', 'lot', 'like', 'parmesan', 'pizza', 'anything', 'else', '.']\n",
      "===================NLTK Tokenizer REMOVED PUNCTUATION===================\n",
      "['Despite', 'this', 'their', 'margherita', 'pizza', 'was', 'seriously', 'underwhelming', 'the', 'way', 'the', 'basil', 'was', 'on', 'the', 'pizza', 'was', 'a', 'little', 'sad', 'but', 'the', 'real', 'killer', 'was', 'the', 'apparent', 'lack', 'of', 'fresh', 'mozzarella', 'it', 'tasted', 'a', 'lot', 'more', 'like', 'a', 'parmesan', 'pizza', 'than', 'anything', 'else']\n",
      "===================NLTK Tokenizer REMOVED TAGS===================\n",
      "['Despite', 'this', ',', 'their', 'margherita', 'pizza', 'was', 'seriously', 'underwhelming', '-', 'the', 'way', 'the', 'basil', 'was', 'on', 'the', 'pizza', 'was', 'a', 'little', 'sad', 'but', 'the', 'real', 'killer', 'was', 'the', 'apparent', 'lack', 'of', 'fresh', 'mozzarella', '-', 'it', 'tasted', 'a', 'lot', 'more', 'like', 'a', 'parmesan', 'pizza', 'than', 'anything', 'else', '.']\n",
      "===================NLTK Tokenizer REMOVED CHARS AND DIGITS===================\n",
      "['Despite', 'this', 'their', 'margherita', 'pizza', 'was', 'seriously', 'underwhelming', 'the', 'way', 'the', 'basil', 'was', 'on', 'the', 'pizza', 'was', 'a', 'little', 'sad', 'but', 'the', 'real', 'killer', 'was', 'the', 'apparent', 'lack', 'of', 'fresh', 'mozzarella', 'it', 'tasted', 'a', 'lot', 'more', 'like', 'a', 'parmesan', 'pizza', 'than', 'anything', 'else']\n",
      "===================NLTK Tokenizer STEMMING APPLIED===================\n",
      "['despit', 'thi', ',', 'their', 'margherita', 'pizza', 'wa', 'serious', 'underwhelm', '-', 'the', 'way', 'the', 'basil', 'wa', 'on', 'the', 'pizza', 'wa', 'a', 'littl', 'sad', 'but', 'the', 'real', 'killer', 'wa', 'the', 'appar', 'lack', 'of', 'fresh', 'mozzarella', '-', 'it', 'tast', 'a', 'lot', 'more', 'like', 'a', 'parmesan', 'pizza', 'than', 'anyth', 'els', '.']\n",
      "===================NLTK Tokenizer LEMMATIZATION APPLIED===================\n",
      "['Despite', 'this', ',', 'their', 'margherita', 'pizza', 'wa', 'seriously', 'underwhelming', '-', 'the', 'way', 'the', 'basil', 'wa', 'on', 'the', 'pizza', 'wa', 'a', 'little', 'sad', 'but', 'the', 'real', 'killer', 'wa', 'the', 'apparent', 'lack', 'of', 'fresh', 'mozzarella', '-', 'it', 'tasted', 'a', 'lot', 'more', 'like', 'a', 'parmesan', 'pizza', 'than', 'anything', 'else', '.']\n",
      "Just seemed like a really strange thing to skimp out on, and based on other pictures it seems like going super light on the cheese may just be the standard here.\n",
      "===================NLTK Tokenizer===================\n",
      "['Just', 'seemed', 'like', 'a', 'really', 'strange', 'thing', 'to', 'skimp', 'out', 'on', ',', 'and', 'based', 'on', 'other', 'pictures', 'it', 'seems', 'like', 'going', 'super', 'light', 'on', 'the', 'cheese', 'may', 'just', 'be', 'the', 'standard', 'here', '.']\n",
      "===================NLTK Word NGRAM Tokenizer 2 words===================\n",
      "['Just seemed', 'seemed like', 'like a', 'a really', 'really strange', 'strange thing', 'thing to', 'to skimp', 'skimp out', 'out on', 'on ,', ', and', 'and based', 'based on', 'on other', 'other pictures', 'pictures it', 'it seems', 'seems like', 'like going', 'going super', 'super light', 'light on', 'on the', 'the cheese', 'cheese may', 'may just', 'just be', 'be the', 'the standard', 'standard here', 'here .']\n",
      "===================NLTK Word NGRAM Tokenizer 3 words===================\n",
      "['Just seemed like', 'seemed like a', 'like a really', 'a really strange', 'really strange thing', 'strange thing to', 'thing to skimp', 'to skimp out', 'skimp out on', 'out on ,', 'on , and', ', and based', 'and based on', 'based on other', 'on other pictures', 'other pictures it', 'pictures it seems', 'it seems like', 'seems like going', 'like going super', 'going super light', 'super light on', 'light on the', 'on the cheese', 'the cheese may', 'cheese may just', 'may just be', 'just be the', 'be the standard', 'the standard here', 'standard here .']\n",
      "===================Phrase Machine===================\n",
      "strange thing\n",
      "other pictures\n",
      "super light\n",
      "super light on the cheese\n",
      "light on the cheese\n",
      "===================Rake===================\n",
      "['seems like going super light', 'really strange thing', 'seemed like', 'cheese may', 'standard', 'skimp', 'pictures', 'based']\n",
      "===================NLTK Tokenizer===================\n",
      "['Just', 'seemed', 'like', 'a', 'really', 'strange', 'thing', 'to', 'skimp', 'out', 'on', ',', 'and', 'based', 'on', 'other', 'pictures', 'it', 'seems', 'like', 'going', 'super', 'light', 'on', 'the', 'cheese', 'may', 'just', 'be', 'the', 'standard', 'here', '.']\n",
      "===================NLTK Tokenizer LOWER CASE===================\n",
      "['just', 'seemed', 'like', 'a', 'really', 'strange', 'thing', 'to', 'skimp', 'out', 'on', ',', 'and', 'based', 'on', 'other', 'pictures', 'it', 'seems', 'like', 'going', 'super', 'light', 'on', 'the', 'cheese', 'may', 'just', 'be', 'the', 'standard', 'here', '.']\n",
      "===================NLTK Tokenizer REMOVE STOP WORDS===================\n",
      "['Just', 'seemed', 'like', 'really', 'strange', 'thing', 'skimp', ',', 'based', 'pictures', 'seems', 'like', 'going', 'super', 'light', 'cheese', 'may', 'standard', '.']\n",
      "===================NLTK Tokenizer REMOVED PUNCTUATION===================\n",
      "['Just', 'seemed', 'like', 'a', 'really', 'strange', 'thing', 'to', 'skimp', 'out', 'on', 'and', 'based', 'on', 'other', 'pictures', 'it', 'seems', 'like', 'going', 'super', 'light', 'on', 'the', 'cheese', 'may', 'just', 'be', 'the', 'standard', 'here']\n",
      "===================NLTK Tokenizer REMOVED TAGS===================\n",
      "['Just', 'seemed', 'like', 'a', 'really', 'strange', 'thing', 'to', 'skimp', 'out', 'on', ',', 'and', 'based', 'on', 'other', 'pictures', 'it', 'seems', 'like', 'going', 'super', 'light', 'on', 'the', 'cheese', 'may', 'just', 'be', 'the', 'standard', 'here', '.']\n",
      "===================NLTK Tokenizer REMOVED CHARS AND DIGITS===================\n",
      "['Just', 'seemed', 'like', 'a', 'really', 'strange', 'thing', 'to', 'skimp', 'out', 'on', 'and', 'based', 'on', 'other', 'pictures', 'it', 'seems', 'like', 'going', 'super', 'light', 'on', 'the', 'cheese', 'may', 'just', 'be', 'the', 'standard', 'here']\n",
      "===================NLTK Tokenizer STEMMING APPLIED===================\n",
      "['just', 'seem', 'like', 'a', 'realli', 'strang', 'thing', 'to', 'skimp', 'out', 'on', ',', 'and', 'base', 'on', 'other', 'pictur', 'it', 'seem', 'like', 'go', 'super', 'light', 'on', 'the', 'chees', 'may', 'just', 'be', 'the', 'standard', 'here', '.']\n",
      "===================NLTK Tokenizer LEMMATIZATION APPLIED===================\n",
      "['Just', 'seemed', 'like', 'a', 'really', 'strange', 'thing', 'to', 'skimp', 'out', 'on', ',', 'and', 'based', 'on', 'other', 'picture', 'it', 'seems', 'like', 'going', 'super', 'light', 'on', 'the', 'cheese', 'may', 'just', 'be', 'the', 'standard', 'here', '.']\n",
      "In any case, I think there are better places to go for pizza on the island, thin-crust or otherwise (especially for the price!!)\n",
      "===================NLTK Tokenizer===================\n",
      "['In', 'any', 'case', ',', 'I', 'think', 'there', 'are', 'better', 'places', 'to', 'go', 'for', 'pizza', 'on', 'the', 'island', ',', 'thin-crust', 'or', 'otherwise', '(', 'especially', 'for', 'the', 'price', '!', '!', ')']\n",
      "===================NLTK Word NGRAM Tokenizer 2 words===================\n",
      "['In any', 'any case', 'case ,', ', I', 'I think', 'think there', 'there are', 'are better', 'better places', 'places to', 'to go', 'go for', 'for pizza', 'pizza on', 'on the', 'the island', 'island ,', ', thin-crust', 'thin-crust or', 'or otherwise', 'otherwise (', '( especially', 'especially for', 'for the', 'the price', 'price !', '! !', '! )']\n",
      "===================NLTK Word NGRAM Tokenizer 3 words===================\n",
      "['In any case', 'any case ,', 'case , I', ', I think', 'I think there', 'think there are', 'there are better', 'are better places', 'better places to', 'places to go', 'to go for', 'go for pizza', 'for pizza on', 'pizza on the', 'on the island', 'the island ,', 'island , thin-crust', ', thin-crust or', 'thin-crust or otherwise', 'or otherwise (', 'otherwise ( especially', '( especially for', 'especially for the', 'for the price', 'the price !', 'price ! !', '! ! )']\n",
      "===================Phrase Machine===================\n",
      "better places\n",
      "pizza on the island\n",
      "===================Rake===================\n",
      "['price !!)', 'better places', 'think', 'thin', 'pizza', 'otherwise', 'island', 'go', 'especially', 'crust', 'case']\n",
      "===================NLTK Tokenizer===================\n",
      "['In', 'any', 'case', ',', 'I', 'think', 'there', 'are', 'better', 'places', 'to', 'go', 'for', 'pizza', 'on', 'the', 'island', ',', 'thin-crust', 'or', 'otherwise', '(', 'especially', 'for', 'the', 'price', '!', '!', ')']\n",
      "===================NLTK Tokenizer LOWER CASE===================\n",
      "['in', 'any', 'case', ',', 'i', 'think', 'there', 'are', 'better', 'places', 'to', 'go', 'for', 'pizza', 'on', 'the', 'island', ',', 'thin-crust', 'or', 'otherwise', '(', 'especially', 'for', 'the', 'price', '!', '!', ')']\n",
      "===================NLTK Tokenizer REMOVE STOP WORDS===================\n",
      "['In', 'case', ',', 'I', 'think', 'better', 'places', 'go', 'pizza', 'island', ',', 'thin-crust', 'otherwise', '(', 'especially', 'price', '!', '!', ')']\n",
      "===================NLTK Tokenizer REMOVED PUNCTUATION===================\n",
      "['In', 'any', 'case', 'I', 'think', 'there', 'are', 'better', 'places', 'to', 'go', 'for', 'pizza', 'on', 'the', 'island', 'thin', 'crust', 'or', 'otherwise', 'especially', 'for', 'the', 'price']\n",
      "===================NLTK Tokenizer REMOVED TAGS===================\n",
      "['In', 'any', 'case', ',', 'I', 'think', 'there', 'are', 'better', 'places', 'to', 'go', 'for', 'pizza', 'on', 'the', 'island', ',', 'thin-crust', 'or', 'otherwise', '(', 'especially', 'for', 'the', 'price', '!', '!', ')']\n",
      "===================NLTK Tokenizer REMOVED CHARS AND DIGITS===================\n",
      "['In', 'any', 'case', 'I', 'think', 'there', 'are', 'better', 'places', 'to', 'go', 'for', 'pizza', 'on', 'the', 'island', 'thin', 'crust', 'or', 'otherwise', 'especially', 'for', 'the', 'price']\n",
      "===================NLTK Tokenizer STEMMING APPLIED===================\n",
      "['in', 'ani', 'case', ',', 'i', 'think', 'there', 'are', 'better', 'place', 'to', 'go', 'for', 'pizza', 'on', 'the', 'island', ',', 'thin-crust', 'or', 'otherwis', '(', 'especi', 'for', 'the', 'price', '!', '!', ')']\n",
      "===================NLTK Tokenizer LEMMATIZATION APPLIED===================\n",
      "['In', 'any', 'case', ',', 'I', 'think', 'there', 'are', 'better', 'place', 'to', 'go', 'for', 'pizza', 'on', 'the', 'island', ',', 'thin-crust', 'or', 'otherwise', '(', 'especially', 'for', 'the', 'price', '!', '!', ')']\n",
      "I didn't really take any particular issue with the noodles themselves (they weren't *unpleasant* to eat or anything) but the texture wasn't amazing and they've just never really impressed.\n",
      "===================NLTK Tokenizer===================\n",
      "['I', 'did', \"n't\", 'really', 'take', 'any', 'particular', 'issue', 'with', 'the', 'noodles', 'themselves', '(', 'they', 'were', \"n't\", '*', 'unpleasant', '*', 'to', 'eat', 'or', 'anything', ')', 'but', 'the', 'texture', 'was', \"n't\", 'amazing', 'and', 'they', \"'ve\", 'just', 'never', 'really', 'impressed', '.']\n",
      "===================NLTK Word NGRAM Tokenizer 2 words===================\n",
      "['I did', \"did n't\", \"n't really\", 'really take', 'take any', 'any particular', 'particular issue', 'issue with', 'with the', 'the noodles', 'noodles themselves', 'themselves (', '( they', 'they were', \"were n't\", \"n't *\", '* unpleasant', 'unpleasant *', '* to', 'to eat', 'eat or', 'or anything', 'anything )', ') but', 'but the', 'the texture', 'texture was', \"was n't\", \"n't amazing\", 'amazing and', 'and they', \"they 've\", \"'ve just\", 'just never', 'never really', 'really impressed', 'impressed .']\n",
      "===================NLTK Word NGRAM Tokenizer 3 words===================\n",
      "[\"I did n't\", \"did n't really\", \"n't really take\", 'really take any', 'take any particular', 'any particular issue', 'particular issue with', 'issue with the', 'with the noodles', 'the noodles themselves', 'noodles themselves (', 'themselves ( they', '( they were', \"they were n't\", \"were n't *\", \"n't * unpleasant\", '* unpleasant *', 'unpleasant * to', '* to eat', 'to eat or', 'eat or anything', 'or anything )', 'anything ) but', ') but the', 'but the texture', 'the texture was', \"texture was n't\", \"was n't amazing\", \"n't amazing and\", 'amazing and they', \"and they 've\", \"they 've just\", \"'ve just never\", 'just never really', 'never really impressed', 'really impressed .']\n",
      "===================Phrase Machine===================\n",
      "particular issue\n",
      "particular issue with the noodles\n",
      "issue with the noodles\n",
      "===================Rake===================\n",
      "['never really impressed', 'really take', 'particular issue', 'unpleasant', 'texture', 'noodles', 'eat', 'anything', 'amazing']\n",
      "===================NLTK Tokenizer===================\n",
      "['I', 'did', \"n't\", 'really', 'take', 'any', 'particular', 'issue', 'with', 'the', 'noodles', 'themselves', '(', 'they', 'were', \"n't\", '*', 'unpleasant', '*', 'to', 'eat', 'or', 'anything', ')', 'but', 'the', 'texture', 'was', \"n't\", 'amazing', 'and', 'they', \"'ve\", 'just', 'never', 'really', 'impressed', '.']\n",
      "===================NLTK Tokenizer LOWER CASE===================\n",
      "['i', 'did', \"n't\", 'really', 'take', 'any', 'particular', 'issue', 'with', 'the', 'noodles', 'themselves', '(', 'they', 'were', \"n't\", '*', 'unpleasant', '*', 'to', 'eat', 'or', 'anything', ')', 'but', 'the', 'texture', 'was', \"n't\", 'amazing', 'and', 'they', \"'ve\", 'just', 'never', 'really', 'impressed', '.']\n",
      "===================NLTK Tokenizer REMOVE STOP WORDS===================\n",
      "['I', \"n't\", 'really', 'take', 'particular', 'issue', 'noodles', '(', \"n't\", '*', 'unpleasant', '*', 'eat', 'anything', ')', 'texture', \"n't\", 'amazing', \"'ve\", 'never', 'really', 'impressed', '.']\n",
      "===================NLTK Tokenizer REMOVED PUNCTUATION===================\n",
      "['I', 'didn', 't', 'really', 'take', 'any', 'particular', 'issue', 'with', 'the', 'noodles', 'themselves', 'they', 'weren', 't', 'unpleasant', 'to', 'eat', 'or', 'anything', 'but', 'the', 'texture', 'wasn', 't', 'amazing', 'and', 'they', 've', 'just', 'never', 'really', 'impressed']\n",
      "===================NLTK Tokenizer REMOVED TAGS===================\n",
      "['I', 'did', \"n't\", 'really', 'take', 'any', 'particular', 'issue', 'with', 'the', 'noodles', 'themselves', '(', 'they', 'were', \"n't\", '*', 'unpleasant', '*', 'to', 'eat', 'or', 'anything', ')', 'but', 'the', 'texture', 'was', \"n't\", 'amazing', 'and', 'they', \"'ve\", 'just', 'never', 'really', 'impressed', '.']\n",
      "===================NLTK Tokenizer REMOVED CHARS AND DIGITS===================\n",
      "['I', 'didn', 't', 'really', 'take', 'any', 'particular', 'issue', 'with', 'the', 'noodles', 'themselves', 'they', 'weren', 't', 'unpleasant', 'to', 'eat', 'or', 'anything', 'but', 'the', 'texture', 'wasn', 't', 'amazing', 'and', 'they', 've', 'just', 'never', 'really', 'impressed']\n",
      "===================NLTK Tokenizer STEMMING APPLIED===================\n",
      "['i', 'did', \"n't\", 'realli', 'take', 'ani', 'particular', 'issu', 'with', 'the', 'noodl', 'themselv', '(', 'they', 'were', \"n't\", '*', 'unpleas', '*', 'to', 'eat', 'or', 'anyth', ')', 'but', 'the', 'textur', 'wa', \"n't\", 'amaz', 'and', 'they', \"'ve\", 'just', 'never', 'realli', 'impress', '.']\n",
      "===================NLTK Tokenizer LEMMATIZATION APPLIED===================\n",
      "['I', 'did', \"n't\", 'really', 'take', 'any', 'particular', 'issue', 'with', 'the', 'noodle', 'themselves', '(', 'they', 'were', \"n't\", '*', 'unpleasant', '*', 'to', 'eat', 'or', 'anything', ')', 'but', 'the', 'texture', 'wa', \"n't\", 'amazing', 'and', 'they', \"'ve\", 'just', 'never', 'really', 'impressed', '.']\n",
      "Additionally, it's a little strange how long it took to get food given how fast fresh pasta takes to cook, their having sauces pre-prepared, and the size of their kitchen.\n",
      "===================NLTK Tokenizer===================\n",
      "['Additionally', ',', 'it', \"'s\", 'a', 'little', 'strange', 'how', 'long', 'it', 'took', 'to', 'get', 'food', 'given', 'how', 'fast', 'fresh', 'pasta', 'takes', 'to', 'cook', ',', 'their', 'having', 'sauces', 'pre-prepared', ',', 'and', 'the', 'size', 'of', 'their', 'kitchen', '.']\n",
      "===================NLTK Word NGRAM Tokenizer 2 words===================\n",
      "['Additionally ,', ', it', \"it 's\", \"'s a\", 'a little', 'little strange', 'strange how', 'how long', 'long it', 'it took', 'took to', 'to get', 'get food', 'food given', 'given how', 'how fast', 'fast fresh', 'fresh pasta', 'pasta takes', 'takes to', 'to cook', 'cook ,', ', their', 'their having', 'having sauces', 'sauces pre-prepared', 'pre-prepared ,', ', and', 'and the', 'the size', 'size of', 'of their', 'their kitchen', 'kitchen .']\n",
      "===================NLTK Word NGRAM Tokenizer 3 words===================\n",
      "['Additionally , it', \", it 's\", \"it 's a\", \"'s a little\", 'a little strange', 'little strange how', 'strange how long', 'how long it', 'long it took', 'it took to', 'took to get', 'to get food', 'get food given', 'food given how', 'given how fast', 'how fast fresh', 'fast fresh pasta', 'fresh pasta takes', 'pasta takes to', 'takes to cook', 'to cook ,', 'cook , their', ', their having', 'their having sauces', 'having sauces pre-prepared', 'sauces pre-prepared ,', 'pre-prepared , and', ', and the', 'and the size', 'the size of', 'size of their', 'of their kitchen', 'their kitchen .']\n",
      "===================Phrase Machine===================\n",
      "fast fresh pasta\n",
      "fresh pasta\n",
      "===================Rake===================\n",
      "['fast fresh pasta takes', 'get food given', 'sauces pre', 'little strange', 'took', 'size', 'prepared', 'long', 'kitchen', 'cook', 'additionally']\n",
      "===================NLTK Tokenizer===================\n",
      "['Additionally', ',', 'it', \"'s\", 'a', 'little', 'strange', 'how', 'long', 'it', 'took', 'to', 'get', 'food', 'given', 'how', 'fast', 'fresh', 'pasta', 'takes', 'to', 'cook', ',', 'their', 'having', 'sauces', 'pre-prepared', ',', 'and', 'the', 'size', 'of', 'their', 'kitchen', '.']\n",
      "===================NLTK Tokenizer LOWER CASE===================\n",
      "['additionally', ',', 'it', \"'s\", 'a', 'little', 'strange', 'how', 'long', 'it', 'took', 'to', 'get', 'food', 'given', 'how', 'fast', 'fresh', 'pasta', 'takes', 'to', 'cook', ',', 'their', 'having', 'sauces', 'pre-prepared', ',', 'and', 'the', 'size', 'of', 'their', 'kitchen', '.']\n",
      "===================NLTK Tokenizer REMOVE STOP WORDS===================\n",
      "['Additionally', ',', \"'s\", 'little', 'strange', 'long', 'took', 'get', 'food', 'given', 'fast', 'fresh', 'pasta', 'takes', 'cook', ',', 'sauces', 'pre-prepared', ',', 'size', 'kitchen', '.']\n",
      "===================NLTK Tokenizer REMOVED PUNCTUATION===================\n",
      "['Additionally', 'it', 's', 'a', 'little', 'strange', 'how', 'long', 'it', 'took', 'to', 'get', 'food', 'given', 'how', 'fast', 'fresh', 'pasta', 'takes', 'to', 'cook', 'their', 'having', 'sauces', 'pre', 'prepared', 'and', 'the', 'size', 'of', 'their', 'kitchen']\n",
      "===================NLTK Tokenizer REMOVED TAGS===================\n",
      "['Additionally', ',', 'it', \"'s\", 'a', 'little', 'strange', 'how', 'long', 'it', 'took', 'to', 'get', 'food', 'given', 'how', 'fast', 'fresh', 'pasta', 'takes', 'to', 'cook', ',', 'their', 'having', 'sauces', 'pre-prepared', ',', 'and', 'the', 'size', 'of', 'their', 'kitchen', '.']\n",
      "===================NLTK Tokenizer REMOVED CHARS AND DIGITS===================\n",
      "['Additionally', 'it', 's', 'a', 'little', 'strange', 'how', 'long', 'it', 'took', 'to', 'get', 'food', 'given', 'how', 'fast', 'fresh', 'pasta', 'takes', 'to', 'cook', 'their', 'having', 'sauces', 'pre', 'prepared', 'and', 'the', 'size', 'of', 'their', 'kitchen']\n",
      "===================NLTK Tokenizer STEMMING APPLIED===================\n",
      "['addit', ',', 'it', \"'s\", 'a', 'littl', 'strang', 'how', 'long', 'it', 'took', 'to', 'get', 'food', 'given', 'how', 'fast', 'fresh', 'pasta', 'take', 'to', 'cook', ',', 'their', 'have', 'sauc', 'pre-prepar', ',', 'and', 'the', 'size', 'of', 'their', 'kitchen', '.']\n",
      "===================NLTK Tokenizer LEMMATIZATION APPLIED===================\n",
      "['Additionally', ',', 'it', \"'s\", 'a', 'little', 'strange', 'how', 'long', 'it', 'took', 'to', 'get', 'food', 'given', 'how', 'fast', 'fresh', 'pasta', 'take', 'to', 'cook', ',', 'their', 'having', 'sauce', 'pre-prepared', ',', 'and', 'the', 'size', 'of', 'their', 'kitchen', '.']\n",
      "But if you order ahead of time this probably isn't much of an issue - they seem to be doing a lot of take-out business.\n",
      "===================NLTK Tokenizer===================\n",
      "['But', 'if', 'you', 'order', 'ahead', 'of', 'time', 'this', 'probably', 'is', \"n't\", 'much', 'of', 'an', 'issue', '-', 'they', 'seem', 'to', 'be', 'doing', 'a', 'lot', 'of', 'take-out', 'business', '.']\n",
      "===================NLTK Word NGRAM Tokenizer 2 words===================\n",
      "['But if', 'if you', 'you order', 'order ahead', 'ahead of', 'of time', 'time this', 'this probably', 'probably is', \"is n't\", \"n't much\", 'much of', 'of an', 'an issue', 'issue -', '- they', 'they seem', 'seem to', 'to be', 'be doing', 'doing a', 'a lot', 'lot of', 'of take-out', 'take-out business', 'business .']\n",
      "===================NLTK Word NGRAM Tokenizer 3 words===================\n",
      "['But if you', 'if you order', 'you order ahead', 'order ahead of', 'ahead of time', 'of time this', 'time this probably', 'this probably is', \"probably is n't\", \"is n't much\", \"n't much of\", 'much of an', 'of an issue', 'an issue -', 'issue - they', '- they seem', 'they seem to', 'seem to be', 'to be doing', 'be doing a', 'doing a lot', 'a lot of', 'lot of take-out', 'of take-out business', 'take-out business .']\n",
      "===================Phrase Machine===================\n",
      "lot of take-out\n",
      "lot of take-out business\n",
      "take-out business\n",
      "===================Rake===================\n",
      "['order ahead', 'time', 'take', 'seem', 'probably', 'much', 'lot', 'issue', 'business']\n",
      "===================NLTK Tokenizer===================\n",
      "['But', 'if', 'you', 'order', 'ahead', 'of', 'time', 'this', 'probably', 'is', \"n't\", 'much', 'of', 'an', 'issue', '-', 'they', 'seem', 'to', 'be', 'doing', 'a', 'lot', 'of', 'take-out', 'business', '.']\n",
      "===================NLTK Tokenizer LOWER CASE===================\n",
      "['but', 'if', 'you', 'order', 'ahead', 'of', 'time', 'this', 'probably', 'is', \"n't\", 'much', 'of', 'an', 'issue', '-', 'they', 'seem', 'to', 'be', 'doing', 'a', 'lot', 'of', 'take-out', 'business', '.']\n",
      "===================NLTK Tokenizer REMOVE STOP WORDS===================\n",
      "['But', 'order', 'ahead', 'time', 'probably', \"n't\", 'much', 'issue', '-', 'seem', 'lot', 'take-out', 'business', '.']\n",
      "===================NLTK Tokenizer REMOVED PUNCTUATION===================\n",
      "['But', 'if', 'you', 'order', 'ahead', 'of', 'time', 'this', 'probably', 'isn', 't', 'much', 'of', 'an', 'issue', 'they', 'seem', 'to', 'be', 'doing', 'a', 'lot', 'of', 'take', 'out', 'business']\n",
      "===================NLTK Tokenizer REMOVED TAGS===================\n",
      "['But', 'if', 'you', 'order', 'ahead', 'of', 'time', 'this', 'probably', 'is', \"n't\", 'much', 'of', 'an', 'issue', '-', 'they', 'seem', 'to', 'be', 'doing', 'a', 'lot', 'of', 'take-out', 'business', '.']\n",
      "===================NLTK Tokenizer REMOVED CHARS AND DIGITS===================\n",
      "['But', 'if', 'you', 'order', 'ahead', 'of', 'time', 'this', 'probably', 'isn', 't', 'much', 'of', 'an', 'issue', 'they', 'seem', 'to', 'be', 'doing', 'a', 'lot', 'of', 'take', 'out', 'business']\n",
      "===================NLTK Tokenizer STEMMING APPLIED===================\n",
      "['but', 'if', 'you', 'order', 'ahead', 'of', 'time', 'thi', 'probabl', 'is', \"n't\", 'much', 'of', 'an', 'issu', '-', 'they', 'seem', 'to', 'be', 'do', 'a', 'lot', 'of', 'take-out', 'busi', '.']\n",
      "===================NLTK Tokenizer LEMMATIZATION APPLIED===================\n",
      "['But', 'if', 'you', 'order', 'ahead', 'of', 'time', 'this', 'probably', 'is', \"n't\", 'much', 'of', 'an', 'issue', '-', 'they', 'seem', 'to', 'be', 'doing', 'a', 'lot', 'of', 'take-out', 'business', '.']\n",
      "Cannoli was ok, not very sweet.\n",
      "===================NLTK Tokenizer===================\n",
      "['Cannoli', 'was', 'ok', ',', 'not', 'very', 'sweet', '.']\n",
      "===================NLTK Word NGRAM Tokenizer 2 words===================\n",
      "['Cannoli was', 'was ok', 'ok ,', ', not', 'not very', 'very sweet', 'sweet .']\n",
      "===================NLTK Word NGRAM Tokenizer 3 words===================\n",
      "['Cannoli was ok', 'was ok ,', 'ok , not', ', not very', 'not very sweet', 'very sweet .']\n",
      "===================Phrase Machine===================\n",
      "===================Rake===================\n",
      "['sweet', 'ok', 'cannoli']\n",
      "===================NLTK Tokenizer===================\n",
      "['Cannoli', 'was', 'ok', ',', 'not', 'very', 'sweet', '.']\n",
      "===================NLTK Tokenizer LOWER CASE===================\n",
      "['cannoli', 'was', 'ok', ',', 'not', 'very', 'sweet', '.']\n",
      "===================NLTK Tokenizer REMOVE STOP WORDS===================\n",
      "['Cannoli', 'ok', ',', 'sweet', '.']\n",
      "===================NLTK Tokenizer REMOVED PUNCTUATION===================\n",
      "['Cannoli', 'was', 'ok', 'not', 'very', 'sweet']\n",
      "===================NLTK Tokenizer REMOVED TAGS===================\n",
      "['Cannoli', 'was', 'ok', ',', 'not', 'very', 'sweet', '.']\n",
      "===================NLTK Tokenizer REMOVED CHARS AND DIGITS===================\n",
      "['Cannoli', 'was', 'ok', 'not', 'very', 'sweet']\n",
      "===================NLTK Tokenizer STEMMING APPLIED===================\n",
      "['cannoli', 'wa', 'ok', ',', 'not', 'veri', 'sweet', '.']\n",
      "===================NLTK Tokenizer LEMMATIZATION APPLIED===================\n",
      "['Cannoli', 'wa', 'ok', ',', 'not', 'very', 'sweet', '.']\n",
      "Nice of them to have it at such a low price, one of my dining companions felt sure they were store-bought but I would probably still get one again.\n",
      "===================NLTK Tokenizer===================\n",
      "['Nice', 'of', 'them', 'to', 'have', 'it', 'at', 'such', 'a', 'low', 'price', ',', 'one', 'of', 'my', 'dining', 'companions', 'felt', 'sure', 'they', 'were', 'store-bought', 'but', 'I', 'would', 'probably', 'still', 'get', 'one', 'again', '.']\n",
      "===================NLTK Word NGRAM Tokenizer 2 words===================\n",
      "['Nice of', 'of them', 'them to', 'to have', 'have it', 'it at', 'at such', 'such a', 'a low', 'low price', 'price ,', ', one', 'one of', 'of my', 'my dining', 'dining companions', 'companions felt', 'felt sure', 'sure they', 'they were', 'were store-bought', 'store-bought but', 'but I', 'I would', 'would probably', 'probably still', 'still get', 'get one', 'one again', 'again .']\n",
      "===================NLTK Word NGRAM Tokenizer 3 words===================\n",
      "['Nice of them', 'of them to', 'them to have', 'to have it', 'have it at', 'it at such', 'at such a', 'such a low', 'a low price', 'low price ,', 'price , one', ', one of', 'one of my', 'of my dining', 'my dining companions', 'dining companions felt', 'companions felt sure', 'felt sure they', 'sure they were', 'they were store-bought', 'were store-bought but', 'store-bought but I', 'but I would', 'I would probably', 'would probably still', 'probably still get', 'still get one', 'get one again', 'one again .']\n",
      "===================Phrase Machine===================\n",
      "low price\n",
      "===================Rake===================\n",
      "['would probably still get one', 'dining companions felt sure', 'low price', 'one', 'store', 'nice', 'bought']\n",
      "===================NLTK Tokenizer===================\n",
      "['Nice', 'of', 'them', 'to', 'have', 'it', 'at', 'such', 'a', 'low', 'price', ',', 'one', 'of', 'my', 'dining', 'companions', 'felt', 'sure', 'they', 'were', 'store-bought', 'but', 'I', 'would', 'probably', 'still', 'get', 'one', 'again', '.']\n",
      "===================NLTK Tokenizer LOWER CASE===================\n",
      "['nice', 'of', 'them', 'to', 'have', 'it', 'at', 'such', 'a', 'low', 'price', ',', 'one', 'of', 'my', 'dining', 'companions', 'felt', 'sure', 'they', 'were', 'store-bought', 'but', 'i', 'would', 'probably', 'still', 'get', 'one', 'again', '.']\n",
      "===================NLTK Tokenizer REMOVE STOP WORDS===================\n",
      "['Nice', 'low', 'price', ',', 'one', 'dining', 'companions', 'felt', 'sure', 'store-bought', 'I', 'would', 'probably', 'still', 'get', 'one', '.']\n",
      "===================NLTK Tokenizer REMOVED PUNCTUATION===================\n",
      "['Nice', 'of', 'them', 'to', 'have', 'it', 'at', 'such', 'a', 'low', 'price', 'one', 'of', 'my', 'dining', 'companions', 'felt', 'sure', 'they', 'were', 'store', 'bought', 'but', 'I', 'would', 'probably', 'still', 'get', 'one', 'again']\n",
      "===================NLTK Tokenizer REMOVED TAGS===================\n",
      "['Nice', 'of', 'them', 'to', 'have', 'it', 'at', 'such', 'a', 'low', 'price', ',', 'one', 'of', 'my', 'dining', 'companions', 'felt', 'sure', 'they', 'were', 'store-bought', 'but', 'I', 'would', 'probably', 'still', 'get', 'one', 'again', '.']\n",
      "===================NLTK Tokenizer REMOVED CHARS AND DIGITS===================\n",
      "['Nice', 'of', 'them', 'to', 'have', 'it', 'at', 'such', 'a', 'low', 'price', 'one', 'of', 'my', 'dining', 'companions', 'felt', 'sure', 'they', 'were', 'store', 'bought', 'but', 'I', 'would', 'probably', 'still', 'get', 'one', 'again']\n",
      "===================NLTK Tokenizer STEMMING APPLIED===================\n",
      "['nice', 'of', 'them', 'to', 'have', 'it', 'at', 'such', 'a', 'low', 'price', ',', 'one', 'of', 'my', 'dine', 'companion', 'felt', 'sure', 'they', 'were', 'store-bought', 'but', 'i', 'would', 'probabl', 'still', 'get', 'one', 'again', '.']\n",
      "===================NLTK Tokenizer LEMMATIZATION APPLIED===================\n",
      "['Nice', 'of', 'them', 'to', 'have', 'it', 'at', 'such', 'a', 'low', 'price', ',', 'one', 'of', 'my', 'dining', 'companion', 'felt', 'sure', 'they', 'were', 'store-bought', 'but', 'I', 'would', 'probably', 'still', 'get', 'one', 'again', '.']\n",
      "Altogether, it's far from bad food, and the location is pretty nice - they give you a good deal of options for take-home food, I like their \"market\" section.\n",
      "===================NLTK Tokenizer===================\n",
      "['Altogether', ',', 'it', \"'s\", 'far', 'from', 'bad', 'food', ',', 'and', 'the', 'location', 'is', 'pretty', 'nice', '-', 'they', 'give', 'you', 'a', 'good', 'deal', 'of', 'options', 'for', 'take-home', 'food', ',', 'I', 'like', 'their', '``', 'market', \"''\", 'section', '.']\n",
      "===================NLTK Word NGRAM Tokenizer 2 words===================\n",
      "['Altogether ,', ', it', \"it 's\", \"'s far\", 'far from', 'from bad', 'bad food', 'food ,', ', and', 'and the', 'the location', 'location is', 'is pretty', 'pretty nice', 'nice -', '- they', 'they give', 'give you', 'you a', 'a good', 'good deal', 'deal of', 'of options', 'options for', 'for take-home', 'take-home food', 'food ,', ', I', 'I like', 'like their', 'their ``', '`` market', \"market ''\", \"'' section\", 'section .']\n",
      "===================NLTK Word NGRAM Tokenizer 3 words===================\n",
      "['Altogether , it', \", it 's\", \"it 's far\", \"'s far from\", 'far from bad', 'from bad food', 'bad food ,', 'food , and', ', and the', 'and the location', 'the location is', 'location is pretty', 'is pretty nice', 'pretty nice -', 'nice - they', '- they give', 'they give you', 'give you a', 'you a good', 'a good deal', 'good deal of', 'deal of options', 'of options for', 'options for take-home', 'for take-home food', 'take-home food ,', 'food , I', ', I like', 'I like their', 'like their ``', 'their `` market', \"`` market ''\", \"market '' section\", \"'' section .\"]\n",
      "===================Phrase Machine===================\n",
      "bad food\n",
      "good deal\n",
      "good deal of options\n",
      "good deal of options for take-home food\n",
      "deal of options\n",
      "deal of options for take-home food\n",
      "options for take-home food\n",
      "take-home food\n",
      "===================Rake===================\n",
      "['pretty nice', 'home food', 'good deal', 'bad food', 'take', 'section', 'options', 'market', 'location', 'like', 'give', 'far', 'altogether']\n",
      "===================NLTK Tokenizer===================\n",
      "['Altogether', ',', 'it', \"'s\", 'far', 'from', 'bad', 'food', ',', 'and', 'the', 'location', 'is', 'pretty', 'nice', '-', 'they', 'give', 'you', 'a', 'good', 'deal', 'of', 'options', 'for', 'take-home', 'food', ',', 'I', 'like', 'their', '``', 'market', \"''\", 'section', '.']\n",
      "===================NLTK Tokenizer LOWER CASE===================\n",
      "['altogether', ',', 'it', \"'s\", 'far', 'from', 'bad', 'food', ',', 'and', 'the', 'location', 'is', 'pretty', 'nice', '-', 'they', 'give', 'you', 'a', 'good', 'deal', 'of', 'options', 'for', 'take-home', 'food', ',', 'i', 'like', 'their', '``', 'market', \"''\", 'section', '.']\n",
      "===================NLTK Tokenizer REMOVE STOP WORDS===================\n",
      "['Altogether', ',', \"'s\", 'far', 'bad', 'food', ',', 'location', 'pretty', 'nice', '-', 'give', 'good', 'deal', 'options', 'take-home', 'food', ',', 'I', 'like', '``', 'market', \"''\", 'section', '.']\n",
      "===================NLTK Tokenizer REMOVED PUNCTUATION===================\n",
      "['Altogether', 'it', 's', 'far', 'from', 'bad', 'food', 'and', 'the', 'location', 'is', 'pretty', 'nice', 'they', 'give', 'you', 'a', 'good', 'deal', 'of', 'options', 'for', 'take', 'home', 'food', 'I', 'like', 'their', 'market', 'section']\n",
      "===================NLTK Tokenizer REMOVED TAGS===================\n",
      "['Altogether', ',', 'it', \"'s\", 'far', 'from', 'bad', 'food', ',', 'and', 'the', 'location', 'is', 'pretty', 'nice', '-', 'they', 'give', 'you', 'a', 'good', 'deal', 'of', 'options', 'for', 'take-home', 'food', ',', 'I', 'like', 'their', '``', 'market', \"''\", 'section', '.']\n",
      "===================NLTK Tokenizer REMOVED CHARS AND DIGITS===================\n",
      "['Altogether', 'it', 's', 'far', 'from', 'bad', 'food', 'and', 'the', 'location', 'is', 'pretty', 'nice', 'they', 'give', 'you', 'a', 'good', 'deal', 'of', 'options', 'for', 'take', 'home', 'food', 'I', 'like', 'their', 'market', 'section']\n",
      "===================NLTK Tokenizer STEMMING APPLIED===================\n",
      "['altogeth', ',', 'it', \"'s\", 'far', 'from', 'bad', 'food', ',', 'and', 'the', 'locat', 'is', 'pretti', 'nice', '-', 'they', 'give', 'you', 'a', 'good', 'deal', 'of', 'option', 'for', 'take-hom', 'food', ',', 'i', 'like', 'their', '``', 'market', '``', 'section', '.']\n",
      "===================NLTK Tokenizer LEMMATIZATION APPLIED===================\n",
      "['Altogether', ',', 'it', \"'s\", 'far', 'from', 'bad', 'food', ',', 'and', 'the', 'location', 'is', 'pretty', 'nice', '-', 'they', 'give', 'you', 'a', 'good', 'deal', 'of', 'option', 'for', 'take-home', 'food', ',', 'I', 'like', 'their', '``', 'market', '``', 'section', '.']\n",
      "I'm not sure if I'd describe it as a \"must-try\" place - even at its best, it feels expensive for what you get.\n",
      "===================NLTK Tokenizer===================\n",
      "['I', \"'m\", 'not', 'sure', 'if', 'I', \"'d\", 'describe', 'it', 'as', 'a', '``', 'must-try', \"''\", 'place', '-', 'even', 'at', 'its', 'best', ',', 'it', 'feels', 'expensive', 'for', 'what', 'you', 'get', '.']\n",
      "===================NLTK Word NGRAM Tokenizer 2 words===================\n",
      "[\"I 'm\", \"'m not\", 'not sure', 'sure if', 'if I', \"I 'd\", \"'d describe\", 'describe it', 'it as', 'as a', 'a ``', '`` must-try', \"must-try ''\", \"'' place\", 'place -', '- even', 'even at', 'at its', 'its best', 'best ,', ', it', 'it feels', 'feels expensive', 'expensive for', 'for what', 'what you', 'you get', 'get .']\n",
      "===================NLTK Word NGRAM Tokenizer 3 words===================\n",
      "[\"I 'm not\", \"'m not sure\", 'not sure if', 'sure if I', \"if I 'd\", \"I 'd describe\", \"'d describe it\", 'describe it as', 'it as a', 'as a ``', 'a `` must-try', \"`` must-try ''\", \"must-try '' place\", \"'' place -\", 'place - even', '- even at', 'even at its', 'at its best', 'its best ,', 'best , it', ', it feels', 'it feels expensive', 'feels expensive for', 'expensive for what', 'for what you', 'what you get', 'you get .']\n",
      "===================Phrase Machine===================\n",
      "===================Rake===================\n",
      "['feels expensive', 'try', 'sure', 'place', 'must', 'get', 'even', 'describe', 'best']\n",
      "===================NLTK Tokenizer===================\n",
      "['I', \"'m\", 'not', 'sure', 'if', 'I', \"'d\", 'describe', 'it', 'as', 'a', '``', 'must-try', \"''\", 'place', '-', 'even', 'at', 'its', 'best', ',', 'it', 'feels', 'expensive', 'for', 'what', 'you', 'get', '.']\n",
      "===================NLTK Tokenizer LOWER CASE===================\n",
      "['i', \"'m\", 'not', 'sure', 'if', 'i', \"'d\", 'describe', 'it', 'as', 'a', '``', 'must-try', \"''\", 'place', '-', 'even', 'at', 'its', 'best', ',', 'it', 'feels', 'expensive', 'for', 'what', 'you', 'get', '.']\n",
      "===================NLTK Tokenizer REMOVE STOP WORDS===================\n",
      "['I', \"'m\", 'sure', 'I', \"'d\", 'describe', '``', 'must-try', \"''\", 'place', '-', 'even', 'best', ',', 'feels', 'expensive', 'get', '.']\n",
      "===================NLTK Tokenizer REMOVED PUNCTUATION===================\n",
      "['I', 'm', 'not', 'sure', 'if', 'I', 'd', 'describe', 'it', 'as', 'a', 'must', 'try', 'place', 'even', 'at', 'its', 'best', 'it', 'feels', 'expensive', 'for', 'what', 'you', 'get']\n",
      "===================NLTK Tokenizer REMOVED TAGS===================\n",
      "['I', \"'m\", 'not', 'sure', 'if', 'I', \"'d\", 'describe', 'it', 'as', 'a', '``', 'must-try', \"''\", 'place', '-', 'even', 'at', 'its', 'best', ',', 'it', 'feels', 'expensive', 'for', 'what', 'you', 'get', '.']\n",
      "===================NLTK Tokenizer REMOVED CHARS AND DIGITS===================\n",
      "['I', 'm', 'not', 'sure', 'if', 'I', 'd', 'describe', 'it', 'as', 'a', 'must', 'try', 'place', 'even', 'at', 'its', 'best', 'it', 'feels', 'expensive', 'for', 'what', 'you', 'get']\n",
      "===================NLTK Tokenizer STEMMING APPLIED===================\n",
      "['i', \"'m\", 'not', 'sure', 'if', 'i', \"'d\", 'describ', 'it', 'as', 'a', '``', 'must-tri', '``', 'place', '-', 'even', 'at', 'it', 'best', ',', 'it', 'feel', 'expens', 'for', 'what', 'you', 'get', '.']\n",
      "===================NLTK Tokenizer LEMMATIZATION APPLIED===================\n",
      "['I', \"'m\", 'not', 'sure', 'if', 'I', \"'d\", 'describe', 'it', 'a', 'a', '``', 'must-try', '``', 'place', '-', 'even', 'at', 'it', 'best', ',', 'it', 'feel', 'expensive', 'for', 'what', 'you', 'get', '.']\n",
      "Still, I'd say it's one of the better restaurants on Bainbridge if money is no object.\n",
      "===================NLTK Tokenizer===================\n",
      "['Still', ',', 'I', \"'d\", 'say', 'it', \"'s\", 'one', 'of', 'the', 'better', 'restaurants', 'on', 'Bainbridge', 'if', 'money', 'is', 'no', 'object', '.']\n",
      "===================NLTK Word NGRAM Tokenizer 2 words===================\n",
      "['Still ,', ', I', \"I 'd\", \"'d say\", 'say it', \"it 's\", \"'s one\", 'one of', 'of the', 'the better', 'better restaurants', 'restaurants on', 'on Bainbridge', 'Bainbridge if', 'if money', 'money is', 'is no', 'no object', 'object .']\n",
      "===================NLTK Word NGRAM Tokenizer 3 words===================\n",
      "['Still , I', \", I 'd\", \"I 'd say\", \"'d say it\", \"say it 's\", \"it 's one\", \"'s one of\", 'one of the', 'of the better', 'the better restaurants', 'better restaurants on', 'restaurants on Bainbridge', 'on Bainbridge if', 'Bainbridge if money', 'if money is', 'money is no', 'is no object', 'no object .']\n",
      "===================Phrase Machine===================\n",
      "better restaurants\n",
      "better restaurants on bainbridge\n",
      "better restaurants on bainbridge if money\n",
      "restaurants on bainbridge\n",
      "restaurants on bainbridge if money\n",
      "bainbridge if money\n",
      "===================Rake===================\n",
      "['better restaurants', 'still', 'say', 'one', 'object', 'money', 'bainbridge']\n",
      "===================NLTK Tokenizer===================\n",
      "['Still', ',', 'I', \"'d\", 'say', 'it', \"'s\", 'one', 'of', 'the', 'better', 'restaurants', 'on', 'Bainbridge', 'if', 'money', 'is', 'no', 'object', '.']\n",
      "===================NLTK Tokenizer LOWER CASE===================\n",
      "['still', ',', 'i', \"'d\", 'say', 'it', \"'s\", 'one', 'of', 'the', 'better', 'restaurants', 'on', 'bainbridge', 'if', 'money', 'is', 'no', 'object', '.']\n",
      "===================NLTK Tokenizer REMOVE STOP WORDS===================\n",
      "['Still', ',', 'I', \"'d\", 'say', \"'s\", 'one', 'better', 'restaurants', 'Bainbridge', 'money', 'object', '.']\n",
      "===================NLTK Tokenizer REMOVED PUNCTUATION===================\n",
      "['Still', 'I', 'd', 'say', 'it', 's', 'one', 'of', 'the', 'better', 'restaurants', 'on', 'Bainbridge', 'if', 'money', 'is', 'no', 'object']\n",
      "===================NLTK Tokenizer REMOVED TAGS===================\n",
      "['Still', ',', 'I', \"'d\", 'say', 'it', \"'s\", 'one', 'of', 'the', 'better', 'restaurants', 'on', 'Bainbridge', 'if', 'money', 'is', 'no', 'object', '.']\n",
      "===================NLTK Tokenizer REMOVED CHARS AND DIGITS===================\n",
      "['Still', 'I', 'd', 'say', 'it', 's', 'one', 'of', 'the', 'better', 'restaurants', 'on', 'Bainbridge', 'if', 'money', 'is', 'no', 'object']\n",
      "===================NLTK Tokenizer STEMMING APPLIED===================\n",
      "['still', ',', 'i', \"'d\", 'say', 'it', \"'s\", 'one', 'of', 'the', 'better', 'restaur', 'on', 'bainbridg', 'if', 'money', 'is', 'no', 'object', '.']\n",
      "===================NLTK Tokenizer LEMMATIZATION APPLIED===================\n",
      "['Still', ',', 'I', \"'d\", 'say', 'it', \"'s\", 'one', 'of', 'the', 'better', 'restaurant', 'on', 'Bainbridge', 'if', 'money', 'is', 'no', 'object', '.']\n",
      "Kind of an iconic little location (Rolling Bay) to visit off the beaten path if you're a tourist.\n",
      "===================NLTK Tokenizer===================\n",
      "['Kind', 'of', 'an', 'iconic', 'little', 'location', '(', 'Rolling', 'Bay', ')', 'to', 'visit', 'off', 'the', 'beaten', 'path', 'if', 'you', \"'re\", 'a', 'tourist', '.']\n",
      "===================NLTK Word NGRAM Tokenizer 2 words===================\n",
      "['Kind of', 'of an', 'an iconic', 'iconic little', 'little location', 'location (', '( Rolling', 'Rolling Bay', 'Bay )', ') to', 'to visit', 'visit off', 'off the', 'the beaten', 'beaten path', 'path if', 'if you', \"you 're\", \"'re a\", 'a tourist', 'tourist .']\n",
      "===================NLTK Word NGRAM Tokenizer 3 words===================\n",
      "['Kind of an', 'of an iconic', 'an iconic little', 'iconic little location', 'little location (', 'location ( Rolling', '( Rolling Bay', 'Rolling Bay )', 'Bay ) to', ') to visit', 'to visit off', 'visit off the', 'off the beaten', 'the beaten path', 'beaten path if', 'path if you', \"if you 're\", \"you 're a\", \"'re a tourist\", 'a tourist .']\n",
      "===================Phrase Machine===================\n",
      "kind of an iconic little location\n",
      "iconic little location\n",
      "little location\n",
      "rolling bay\n",
      "beaten path\n",
      "===================Rake===================\n",
      "['iconic little location', 'rolling bay', 'beaten path', 'visit', 'tourist', 'kind']\n",
      "===================NLTK Tokenizer===================\n",
      "['Kind', 'of', 'an', 'iconic', 'little', 'location', '(', 'Rolling', 'Bay', ')', 'to', 'visit', 'off', 'the', 'beaten', 'path', 'if', 'you', \"'re\", 'a', 'tourist', '.']\n",
      "===================NLTK Tokenizer LOWER CASE===================\n",
      "['kind', 'of', 'an', 'iconic', 'little', 'location', '(', 'rolling', 'bay', ')', 'to', 'visit', 'off', 'the', 'beaten', 'path', 'if', 'you', \"'re\", 'a', 'tourist', '.']\n",
      "===================NLTK Tokenizer REMOVE STOP WORDS===================\n",
      "['Kind', 'iconic', 'little', 'location', '(', 'Rolling', 'Bay', ')', 'visit', 'beaten', 'path', \"'re\", 'tourist', '.']\n",
      "===================NLTK Tokenizer REMOVED PUNCTUATION===================\n",
      "['Kind', 'of', 'an', 'iconic', 'little', 'location', 'Rolling', 'Bay', 'to', 'visit', 'off', 'the', 'beaten', 'path', 'if', 'you', 're', 'a', 'tourist']\n",
      "===================NLTK Tokenizer REMOVED TAGS===================\n",
      "['Kind', 'of', 'an', 'iconic', 'little', 'location', '(', 'Rolling', 'Bay', ')', 'to', 'visit', 'off', 'the', 'beaten', 'path', 'if', 'you', \"'re\", 'a', 'tourist', '.']\n",
      "===================NLTK Tokenizer REMOVED CHARS AND DIGITS===================\n",
      "['Kind', 'of', 'an', 'iconic', 'little', 'location', 'Rolling', 'Bay', 'to', 'visit', 'off', 'the', 'beaten', 'path', 'if', 'you', 're', 'a', 'tourist']\n",
      "===================NLTK Tokenizer STEMMING APPLIED===================\n",
      "['kind', 'of', 'an', 'icon', 'littl', 'locat', '(', 'roll', 'bay', ')', 'to', 'visit', 'off', 'the', 'beaten', 'path', 'if', 'you', \"'re\", 'a', 'tourist', '.']\n",
      "===================NLTK Tokenizer LEMMATIZATION APPLIED===================\n",
      "['Kind', 'of', 'an', 'iconic', 'little', 'location', '(', 'Rolling', 'Bay', ')', 'to', 'visit', 'off', 'the', 'beaten', 'path', 'if', 'you', \"'re\", 'a', 'tourist', '.']\n",
      "People definitely like this place for a reason.\n",
      "===================NLTK Tokenizer===================\n",
      "['People', 'definitely', 'like', 'this', 'place', 'for', 'a', 'reason', '.']\n",
      "===================NLTK Word NGRAM Tokenizer 2 words===================\n",
      "['People definitely', 'definitely like', 'like this', 'this place', 'place for', 'for a', 'a reason', 'reason .']\n",
      "===================NLTK Word NGRAM Tokenizer 3 words===================\n",
      "['People definitely like', 'definitely like this', 'like this place', 'this place for', 'place for a', 'for a reason', 'a reason .']\n",
      "===================Phrase Machine===================\n",
      "place for a reason\n",
      "===================Rake===================\n",
      "['people definitely like', 'reason', 'place']\n",
      "===================NLTK Tokenizer===================\n",
      "['People', 'definitely', 'like', 'this', 'place', 'for', 'a', 'reason', '.']\n",
      "===================NLTK Tokenizer LOWER CASE===================\n",
      "['people', 'definitely', 'like', 'this', 'place', 'for', 'a', 'reason', '.']\n",
      "===================NLTK Tokenizer REMOVE STOP WORDS===================\n",
      "['People', 'definitely', 'like', 'place', 'reason', '.']\n",
      "===================NLTK Tokenizer REMOVED PUNCTUATION===================\n",
      "['People', 'definitely', 'like', 'this', 'place', 'for', 'a', 'reason']\n",
      "===================NLTK Tokenizer REMOVED TAGS===================\n",
      "['People', 'definitely', 'like', 'this', 'place', 'for', 'a', 'reason', '.']\n",
      "===================NLTK Tokenizer REMOVED CHARS AND DIGITS===================\n",
      "['People', 'definitely', 'like', 'this', 'place', 'for', 'a', 'reason']\n",
      "===================NLTK Tokenizer STEMMING APPLIED===================\n",
      "['peopl', 'definit', 'like', 'thi', 'place', 'for', 'a', 'reason', '.']\n",
      "===================NLTK Tokenizer LEMMATIZATION APPLIED===================\n",
      "['People', 'definitely', 'like', 'this', 'place', 'for', 'a', 'reason', '.']\n"
     ]
    }
   ],
   "source": [
    "#Explore different extractors and difference preprocessing techniques\n",
    "for sentence in sentences:\n",
    "    print(sentence)\n",
    "    print(\"===================NLTK Tokenizer===================\")\n",
    "    print(run_nltk_tokenizer(sentence))\n",
    "    print(\"===================NLTK Word NGRAM Tokenizer 2 words===================\")\n",
    "    print(run_nltk_tokenizer_word_ngrams(sentence,2))\n",
    "    print(\"===================NLTK Word NGRAM Tokenizer 3 words===================\")\n",
    "    print(run_nltk_tokenizer_word_ngrams(sentence,3))\n",
    "    print(\"===================Phrase Machine===================\")\n",
    "    phrases=run_phrase_machine(sentence)\n",
    "    for term in phrases[\"counts\"].keys():\n",
    "        print(term)\n",
    "    print(\"===================Rake===================\")\n",
    "    print(run_rake(sentence))\n",
    "    print(\"===================NLTK Tokenizer===================\")\n",
    "    print(run_nltk_tokenizer((sentence)))\n",
    "    print(\"===================NLTK Tokenizer LOWER CASE===================\")\n",
    "    print(run_nltk_tokenizer(lower_case(sentence)))\n",
    "    print(\"===================NLTK Tokenizer REMOVE STOP WORDS===================\")\n",
    "    print(remove_stop_words(sentence))   \n",
    "    print(\"===================NLTK Tokenizer REMOVED PUNCTUATION===================\")\n",
    "    print(run_nltk_tokenizer(remove_punctuation(sentence)))\n",
    "    print(\"===================NLTK Tokenizer REMOVED TAGS===================\")\n",
    "    print(run_nltk_tokenizer(remove_tags(sentence)))\n",
    "    print(\"===================NLTK Tokenizer REMOVED CHARS AND DIGITS===================\")\n",
    "    print(run_nltk_tokenizer(remove_special_chars_and_digits(sentence)))\n",
    "    print(\"===================NLTK Tokenizer STEMMING APPLIED===================\")\n",
    "    print(run_nltk_tokenizer(apply_stemming(sentence)))\n",
    "    print(\"===================NLTK Tokenizer LEMMATIZATION APPLIED===================\")\n",
    "    print(run_nltk_tokenizer(apply_lemmatization(sentence)))\n",
    "    #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " For their sauces alone, I'm willing to say Via Rosa puts out some of the best-tasting food on the island.\n",
      "All of the sauces I've tried there taste like something homemade, like they took a good deal of time and effort to make.\n",
      "Definitely a step above the average around here.\n",
      "That said, for the price, the pizza and pasta itself fell a little bit short of expectations.\n",
      "The pizza dough itself is very thin, very crisp, and has a nice flavor.\n",
      "Their marinara, like all their other sauces, is bright and tasty.\n",
      "Despite this, their margherita pizza was seriously underwhelming - the way the basil was on the pizza was a little sad but the real killer was the apparent lack of fresh mozzarella - it tasted a lot more like a parmesan pizza than anything else.\n",
      "Just seemed like a really strange thing to skimp out on, and based on other pictures it seems like going super light on the cheese may just be the standard here.\n",
      "In any case, I think there are better places to go for pizza on the island, thin-crust or otherwise (especially for the price!!)\n",
      "I didn't really take any particular issue with the noodles themselves (they weren't *unpleasant* to eat or anything) but the texture wasn't amazing and they've just never really impressed.\n",
      "Additionally, it's a little strange how long it took to get food given how fast fresh pasta takes to cook, their having sauces pre-prepared, and the size of their kitchen.\n",
      "But if you order ahead of time this probably isn't much of an issue - they seem to be doing a lot of take-out business.\n",
      "Cannoli was ok, not very sweet.\n",
      "Nice of them to have it at such a low price, one of my dining companions felt sure they were store-bought but I would probably still get one again.\n",
      "Altogether, it's far from bad food, and the location is pretty nice - they give you a good deal of options for take-home food, I like their \"market\" section.\n",
      "I'm not sure if I'd describe it as a \"must-try\" place - even at its best, it feels expensive for what you get.\n",
      "Still, I'd say it's one of the better restaurants on Bainbridge if money is no object.\n",
      "Kind of an iconic little location (Rolling Bay) to visit off the beaten path if you're a tourist.\n",
      "People definitely like this place for a reason.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "FreqDist({'like': 4, 'pizza': 3, 'island': 2, 'best': 2, 'good deal': 2, 'took': 2, 'time': 2, 'sauces': 2, 'thin': 2, 'lot': 2, ...})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Explore different extractors and difference preprocessing techniques\n",
    "all_terms=[]\n",
    "for sentence in sentences:\n",
    "    print(sentence)\n",
    "    #pick your favorite term extractor\n",
    "    all_terms = all_terms +run_rake(sentence)\n",
    "#get the frequency distribution across the terms\n",
    "fd=get_freq_dist(all_terms)\n",
    "fd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
